---
layout: post
title: 'Week 6: Empirical size and power of Likelihood based tests.' 
description: "Week 6: Empirical size and power of Likelihood based tests."
category: ie
tags: [IE14, teaching, week6]
comments: true  
published: true
status: process
---



Regressions with multiple variables and matrix notation
========================================================




## Monte Carlo estimation of the size and power of Likelihood based tests.

First, we create a function that takes as input a matrix X, the true value of beta2 as well as the number of observations and the number of Monte Carlo iterations. It returns a vector with the average rejection frequency of \\(H0: \beta_2=0 \\).


{% highlight r %}
library("ggplot2")
# Create a function returning mc p-values for each test Inputs: - n the
# number of observations - mc the number of monte carlo iterations - b the
# true value of beta2 - X the X matrix Output:
mcMLtests <- function(n, mc, b, X) {
    
    # The parameter vector
    beta <- c(1, b)
    
    # storage matrix
    LR <- matrix(NA, nrow = mc, ncol = 1)
    LM <- matrix(NA, nrow = mc, ncol = 1)
    W <- matrix(NA, nrow = mc, ncol = 1)
    
    for (m in 1:mc) {
        eps <- rnorm(n, sd = 1)  # standard normal innovations
        
        # Generating the data
        y <- X %*% beta + eps
        
        # Estimating the model under the alternative
        ML1 <- lm(y ~ X)
        # Under the Null
        ML0 <- lm(y ~ X[, 1])
        
        # Storing the residuals
        eps0 <- resid(ML0)
        eps1 <- resid(ML1)
        
        # Storing the estimated betas
        beta0 <- coef(ML0)
        beta1 <- coef(ML1)
        
        # Calculating the MLE of sigma2
        sig0 <- sum(eps0^2)/n
        sig1 <- sum(eps1^2)/n
        
        # Computing the test statistics:
        LR[m] <- n * (log(sig0) - log(sig1))
        W[m] <- (beta1[3]^2)/(sqrt(sig1) * (1/sum(X[, 2]^2)))
        LM[m] <- (t(eps0) %*% X %*% solve(t(X) %*% X) %*% t(X) %*% eps0)/sig0
    }
    
    pval <- c(mean((1 - pchisq(LM, df = 1)) < 0.05), mean((1 - pchisq(LR, df = 1)) < 
        0.05), mean((1 - pchisq(W, df = 1)) < 0.05))
    return(pval)
}
{% endhighlight %}


We use the function created above to run a first experiment with 10 observations (n=10). The true value of beta2 varies in the range \\(\beta_2 = (0,0.05,0.1,...,0.95,1)\\). 


{% highlight r %}

# nbr of obs
n <- 10
# nbr of Monte Carlo iterations
mc <- 1000
# beta2 parameter value
beta2 <- seq(from = 0, to = 1, by = 0.05)

# The storage matrix
mc10 <- matrix(NA, nrow = length(beta2), ncol = 3)
rownames(mc10) <- beta2
colnames(mc10) <- c("LM", "LR", "W")

# Same set of controls for every experiment
X <- matrix(rnorm(n * 2), nrow = n, ncol = 2)

# loop counter
i <- 1

# Monte Carlo experiment
for (b in beta2) {
    mc10[i, ] <- mcMLtests(n, mc, b, X)
    i <- i + 1
}

# Now preparing a plot of the results:
mc10 <- melt(mc10)
head(mc10)
{% endhighlight %}



{% highlight text %}
##   Var1 Var2 value
## 1 0.00   LM 0.059
## 2 0.05   LM 0.083
## 3 0.10   LM 0.083
## 4 0.15   LM 0.089
## 5 0.20   LM 0.115
## 6 0.25   LM 0.132
{% endhighlight %}



{% highlight r %}
colnames(mc10) <- c("b", "Test", "Power")

gg.mc10 <- ggplot(mc10, aes(x = b, y = Power, colour = Test)) + geom_line() + 
    ggtitle("Rejection frequency of H0: beta2=0")
print(gg.mc10)
{% endhighlight %}

![center](/figs/2014-03-09-IE14-W6_rmd/mc10.png) 


Another experiment with 100 observations and \\( \beta_2 =0,0.025,0.05,...,0.475,0.5 \\):


{% highlight r %}

# nbr of obs
n <- 100
# nbr of Monte Carlo iterations
mc <- 1000
# beta2 parameter value
beta2 <- seq(from = 0, to = 0.5, by = 0.025)

# The storage matrix
mc100 <- matrix(NA, nrow = length(beta2), ncol = 3)
rownames(mc100) <- beta2
colnames(mc100) <- c("LM", "LR", "W")

# Same set of controls for every experiment
X <- matrix(rnorm(n * 2), nrow = n, ncol = 2)

# loop counter
i <- 1

# Monte Carlo experiment
for (b in beta2) {
    mc100[i, ] <- mcMLtests(n, mc, b, X)
    i <- i + 1
}

# Now preparing a plot of the results:
mc100 <- melt(mc100)
head(mc100)
{% endhighlight %}



{% highlight text %}
##    Var1 Var2 value
## 1 0.000   LM 0.056
## 2 0.025   LM 0.068
## 3 0.050   LM 0.076
## 4 0.075   LM 0.116
## 5 0.100   LM 0.147
## 6 0.125   LM 0.198
{% endhighlight %}



{% highlight r %}
colnames(mc100) <- c("b", "Test", "Power")

gg.mc100 <- ggplot(mc100, aes(x = b, y = Power, colour = Test)) + geom_line() + 
    ggtitle("Rejection frequency of H0: beta2=0")
print(gg.mc100)
{% endhighlight %}

![center](/figs/2014-03-09-IE14-W6_rmd/mc100.png) 




Same experiment as before, but this time X is t-distributed with 3 degrees of freedom.



{% highlight r %}

# The storage matrix
mc100X <- matrix(NA, nrow = length(beta2), ncol = 3)
rownames(mc100X) <- beta2
colnames(mc100X) <- c("LM", "LR", "W")

# Same set of controls for every experiment
X <- matrix(rt(n * 2, df = 3), ncol = 2, nrow = n)

# loop counter
i <- 1

# Monte Carlo experiment
for (b in beta2) {
    mc100X[i, ] <- mcMLtests(n, mc, b, X)
    i <- i + 1
}

# Now preparing a plot of the results:
mc100X <- melt(mc100X)
head(mc100X)
{% endhighlight %}



{% highlight text %}
##    Var1 Var2 value
## 1 0.000   LM 0.053
## 2 0.025   LM 0.070
## 3 0.050   LM 0.173
## 4 0.075   LM 0.317
## 5 0.100   LM 0.522
## 6 0.125   LM 0.686
{% endhighlight %}



{% highlight r %}
colnames(mc100X) <- c("b", "Test", "Power")

gg.mc100X <- ggplot(mc100X, aes(x = b, y = Power, colour = Test)) + geom_line() + 
    ggtitle("Rejection frequency of H0: beta2=0")
print(gg.mc100X)
{% endhighlight %}

![center](/figs/2014-03-09-IE14-W6_rmd/mc100X.png) 


